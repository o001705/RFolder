text <- c("Operations need to have demand forecasts \
in order to establish optimal resource allocation policies. ",
"But, when we make predictions the only thing that we assure\
is the occurrence of prediction errors. ",
"Fortunately, there is no need to be 100% accurate to succeed, \
we just need to perform better than our competitors. ",
"In this exercise we will learn a practical approach to \
predict using the forecast package. ")
text
text <- c("Operations need to have demand forecasts in order to establish optimal resource allocation policies. ",
"But, when we make predictions the only thing that we assure is the occurrence of prediction errors. ",
"Fortunately, there is no need to be 100% accurate to succeed, we just need to perform better than our competitors. ",
"In this exercise we will learn a practical approach to predict using the forecast package. ")
text
text_df <- data_frame(line = 1:nrow(c), text = text)
text_df <- data_frame(line = 1:length(c), text = text)
library(dplyr)
install.packages(dplyr)
install.packages("dplyr")
library(dplyr)
text_df <- data_frame(line = 1:length(c), text = text)
text_df
length(c)
nrows(c)
nrow(c)
size(c)
dim(text)
size(text)
length(text)
text_df <- data_frame(line = 1:lenght(text), text = text)
text_df
text_df <- data_frame(line = 1:4, text = text)
text_df
list_len <- lenght(text)
list_len <- length(text)
list_len
text_df <- data_frame(line = 1:list_len, text = text)
text_df
lines <- 0
for(i in 1:list_len){
lines <- lines + grepl("[p][r][e][d][i][c][t]", text_df[i,2])
}
lines
install.packages("tidytext")
library(tidytext)
text_df %>%
unnest_tokens(word, text)%>%
count(word, sort = TRUE)
data(stop_words)
install.packages("gutenbergr")
library(TextAnalytics1)
taex1()
?anti_join
taex1()
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1()
stop_words
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1()
?tbl_vars
stop_words
taex1()
tbl_vars(stop_words)
library(TextAnalytics1)
taex1()
taex1()
taex1()
taex1()
library(TextAnalytics1)
taex1()
?anti_join
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1()
?gutenbergr
?gutenberg
?gutenberg_download
?gutenbergr_download
gutenberg_download(768)
library(gutenbergr)
gutenberg_download(768)
library(TextAnalytics1)
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1()
library(TextAnalytics1)
taex1(2)
taex1(100)
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
taex1(100)
taex1(1)
library(tidytext)
sentiments
get_sentiments("bing")
get_sentiments("afinn")
install.packages("janeaustenr")
install.packages("janeaustenr")
install.packages("stringr")
library(janeaustenr)
library(stringr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
?group_by
??group_by
library(dplyr)
library(janeaustenr)
library(stringr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
??unnest_tokens
library(tidytext)
library(janeaustenr)
library(stringr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
print(tidy_books)
nrcjoy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrcjoy) %>%
count(word, sort = TRUE)
nrcjoy <- get_sentiments("bing") %>%
filter(sentiment == "negative")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrcjoy) %>%
count(word, sort = TRUE)
nrcjoy <- get_sentiments("bing") %>%
filter(sentiment == "negative")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrcjoy) %>%
count(word, sort = TRUE)
nrcjoy <- get_sentiments("bing") %>%
filter(sentiment == "positive")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrcjoy) %>%
count(word, sort = TRUE)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
??spread
install.packages("tidyr")
install.packages("tidyr")
library(tidytext)
library(tidyr)
library(janeaustenr)
library(stringr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
library(dplyr)
library(janeaustenr)
library(stringr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
library(ggplot2)
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
print(tidy_books)
library(TextAnalytics1)
taex1(1)
?count
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
get_sentiments("bing")
library(TextAnalytics1)
taex1()
taex1(100)
library(TextAnalytics1)
taex1(100)
?spread
book
?count
library(TextAnalytics1)
taex1(100)
library(TextAnalytics1)
taex1(100)
?ggplot
?aes
?facet_wrap
taex1(100)
?aes
taex1(100)
taex1(100)
taex1(100)
taex1(100)
?count
taex1(100)
taex1(100)
book
taex1(100)
taex1(100)
?ggplot
?aes
taex1(100)
taex1(100)
taex1(100)
taex1(100)
taex1(1)
taex1(1)
taex1(1)
taex1(2)
taex1(50)
taex1(50)
taex1(120)
taex1(120)
taex1(50)
taex1(120)
taex1(125)
taex1(127)
taex1(127)
taex1(128)
taex1(254)
taex1(255)
taex1(257)
